#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Streamlit Kçº¿ä¸æˆäº¤æµåˆ†æç½‘é¡µåº”ç”¨

æä¾›æ‰‹åŠ¨å’Œè‡ªåŠ¨ K çº¿åŠæˆäº¤æµåˆ†æåŠŸèƒ½ã€‚
æ‰‹åŠ¨åˆ†æå¸¦æœ‰åŸºäºæ—¶é—´çš„ç¼“å­˜ï¼Œé¿å…çŸ­æœŸå†…é‡å¤è¯·æ±‚ã€‚
è‡ªåŠ¨åˆ†æä¾èµ–åå°è„šæœ¬å®šæ—¶ç”Ÿæˆç»“æœæ–‡ä»¶ã€‚
"""

import streamlit as st
import pandas as pd
import logging
import json
import os
from datetime import datetime, timedelta
import time
from binance.client import Client # ç”¨äºè·å– Top 20 äº¤æ˜“å¯¹

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
try:
    # ç§»é™¤ 'é…ç½®' æ¨¡å—çš„å¯¼å…¥ï¼Œå› ä¸ºå¯†é’¥å°†ä» st.secrets è·å–
    # import é…ç½®
    import æ•°æ®è·å–æ¨¡å— as data_fetcher_module # ä½¿ç”¨ä¸­æ–‡åå¯¼å…¥ï¼Œå¹¶ä½¿ç”¨åˆ«å
    import kçº¿åˆ†ææ¨¡å— as kline_analysis_module # ä½¿ç”¨ä¸­æ–‡åå¯¼å…¥ï¼Œå¹¶ä½¿ç”¨åˆ«å
    import æˆäº¤æµåˆ†æ as æˆäº¤æµç½‘é¡µåˆ†æ # å¯¼å…¥æˆäº¤æµåˆ†ææ¨¡å—ï¼Œä½¿ç”¨ä¸­æ–‡åˆ«å
    MODULE_LOAD_ERROR = None
except ImportError as e:
    MODULE_LOAD_ERROR = e
    # åœ¨åº”ç”¨æ—©æœŸå¤„ç†ï¼Œé¿å…åç»­å› æ¨¡å—ç¼ºå¤±å¼•å‘æ›´å¤šé”™è¯¯
    st.error(f"æ ¸å¿ƒè‡ªå®šä¹‰æ¨¡å—åŠ è½½å¤±è´¥: {e}ã€‚è¯·ç¡®ä¿æ‰€éœ€ .py æ–‡ä»¶å­˜åœ¨ä¸”æ— è¯¯ã€‚")
    st.stop()

# --- å…¨å±€å¸¸é‡ ---
AUTO_KLINE_RESULTS_FILE = 'auto_analysis_results.json' # Kçº¿åå°è„šæœ¬å†™å…¥ç»“æœçš„æ–‡ä»¶å
AUTO_VOLUME_RESULTS_FILE = 'auto_volume_analysis_results.json' # æˆäº¤æµåå°è„šæœ¬å†™å…¥ç»“æœçš„æ–‡ä»¶å
TOP_N_SYMBOLS = 20 # è‡ªåŠ¨åˆ†æçš„ç›®æ ‡æ•°é‡
CACHE_TTL_SECONDS = 60 # æ‰‹åŠ¨åˆ†æç¼“å­˜æ—¶é—´ (ç§’)
AUTO_ANALYSIS_INTERVAL_MINUTES = 5 # è‡ªåŠ¨åˆ†æçš„é—´éš”æ—¶é—´ (åˆ†é’Ÿ)

# --- åˆå§‹åŒ– Session State ---
# ç”¨äºå­˜å‚¨æ‰‹åŠ¨åˆ†æçš„ç»“æœï¼Œä½¿å…¶åœ¨ rerun åä¿ç•™
if 'manual_kline_analysis_result' not in st.session_state:
    st.session_state.manual_kline_analysis_result = None
if 'manual_volume_analysis_result' not in st.session_state: # æ–°å¢ï¼šæˆäº¤é‡æ‰‹åŠ¨åˆ†æç»“æœ
    st.session_state.manual_volume_analysis_result = None

# è®°å½•ä¸Šæ¬¡åˆ†æçš„å‚æ•°ï¼ˆç”¨äºè·¨ Tab é¢„å¡«è¾“å…¥ï¼‰
if 'last_analyzed_symbol' not in st.session_state: # æ–°å¢åˆå§‹åŒ–
    st.session_state.last_analyzed_symbol = None
if 'last_analyzed_market' not in st.session_state: # æ–°å¢åˆå§‹åŒ–
    st.session_state.last_analyzed_market = None

# æ–°å¢ï¼šè®°å½•ä¸Šæ¬¡æˆäº¤é‡åˆ†æçš„å‚æ•°
if 'last_analyzed_volume_symbol' not in st.session_state:
    st.session_state.last_analyzed_volume_symbol = None
if 'last_analyzed_volume_market' not in st.session_state:
    st.session_state.last_analyzed_volume_market = None

# --- æ—¥å¿—é…ç½® ---
log_file_path = os.path.join(os.path.dirname(__file__), 'logs', 'app.log')
os.makedirs(os.path.dirname(log_file_path), exist_ok=True)
logger = logging.getLogger("åˆ†æç½‘é¡µåŠŸèƒ½") # ä½¿ç”¨ç‹¬ç«‹çš„ logger åç§°
if not logger.handlers:
    logger.setLevel(logging.DEBUG)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    # æ§åˆ¶å°è¾“å‡º
    stream_handler = logging.StreamHandler()
    stream_handler.setFormatter(formatter)
    stream_handler.setLevel(logging.DEBUG)
    logger.addHandler(stream_handler)
    # æ–‡ä»¶è¾“å‡º
    file_handler = logging.FileHandler(log_file_path, encoding='utf-8')
    file_handler.setFormatter(formatter)
    file_handler.setLevel(logging.DEBUG)
    logger.addHandler(file_handler)
    logger.propagate = False
logger.info("åˆ†æç½‘é¡µåŠŸèƒ½åº”ç”¨å¯åŠ¨ï¼Œæ—¥å¿—åˆå§‹åŒ–å®Œæˆ (Debug Level Enabled)ã€‚")

# --- åˆå§‹åŒ–æ ¸å¿ƒæ¨¡å— ---
# ... (å¸å®‰ Client åˆå§‹åŒ–ä¿®æ”¹å¦‚ä¸‹) ...
binance_client = None # ç”¨äºè·å–è¡Œæƒ…æ•°æ®

try:
    # 1. ä» Streamlit Secrets è·å– API å¯†é’¥
    #    å‡è®¾ä½ åœ¨ Streamlit Cloud ä¸Šé…ç½®çš„ Secrets åç§°æ˜¯ BINANCE_API_KEY å’Œ BINANCE_API_SECRET
    #    å¦‚æœä¸æ˜¯ï¼Œè¯·åœ¨ Cloud ä¸Šåˆ›å»ºå®ƒä»¬ï¼Œæˆ–ä¿®æ”¹è¿™é‡Œçš„é”®å
    api_key = st.secrets.get("BINANCE_API_KEY")
    api_secret = st.secrets.get("BINANCE_API_SECRET")

    if not api_key or not api_secret:
        # å¦‚æœåœ¨ Streamlit Cloud è¿è¡Œä½†æœªè®¾ç½® Secretsï¼Œæˆ–æœ¬åœ°è¿è¡Œä¸”æ—  secrets.toml æ–‡ä»¶
        st.error("æ— æ³•è·å–å¸å®‰ API å¯†é’¥ã€‚è¯·æ£€æŸ¥ Streamlit Cloud çš„ Secrets é…ç½®æˆ–æœ¬åœ°çš„ .streamlit/secrets.toml æ–‡ä»¶ã€‚")
        logger.error("æœªæ‰¾åˆ° API å¯†é’¥ (st.secrets)ã€‚")
        st.stop()
    elif api_key == "YOUR_API_KEY_PLACEHOLDER" or api_secret == "YOUR_API_SECRET_PLACEHOLDER":
        # (å¯é€‰) å¢åŠ å¯¹å ä½ç¬¦çš„æ£€æŸ¥ï¼Œè™½ç„¶ç†è®ºä¸Š Secrets ä¸åº”è®¾ä¸ºå ä½ç¬¦
        st.warning("æ£€æµ‹åˆ° API å¯†é’¥æˆ– Secret ä¸ºå ä½ç¬¦å­—ç¬¦ä¸²ï¼Œè¯·åœ¨ Streamlit Cloud Secrets ä¸­æ›´æ–°ä¸ºçœŸå®å€¼ã€‚")
        logger.warning("API å¯†é’¥/Secret å€¼ä¸ºå ä½ç¬¦ã€‚")
        # ä¸åœæ­¢è¿è¡Œï¼Œä½†ç»™å‡ºè­¦å‘Š

    # 2. å¤„ç†ä»£ç† (ä»ç¯å¢ƒå˜é‡æˆ– 'é…ç½®' æ¨¡å—è¯»å– - 'é…ç½®' æ¨¡å—ä»éœ€ç”¨äºä»£ç†è®¾ç½®)
    #    æ³¨æ„ï¼šå¦‚æœä»£ç†è®¾ç½®ä¹Ÿå¸Œæœ›é€šè¿‡ Secrets ç®¡ç†ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¿®æ”¹
    try:
        import é…ç½® # ä»…ä¸ºä»£ç†è®¾ç½®å¯¼å…¥é…ç½®
        use_proxy_config = getattr(é…ç½®, 'USE_PROXY', False)
        proxy_url_config = getattr(é…ç½®, 'PROXY_URL', None)
    except ImportError:
        # å¦‚æœ é…ç½®.py ä¸å­˜åœ¨æˆ–æ— æ³•å¯¼å…¥ï¼Œåˆ™ä»…ä¾èµ–ç¯å¢ƒå˜é‡
        use_proxy_config = False
        proxy_url_config = None
        logger.info("æœªæ‰¾åˆ° 'é…ç½®.py' æ–‡ä»¶ï¼Œä»£ç†è®¾ç½®å°†ä»…ä¾èµ–ç¯å¢ƒå˜é‡ã€‚")

    use_proxy_env = os.getenv('USE_PROXY', 'false').lower() == 'true'
    use_proxy = use_proxy_env or use_proxy_config

    proxy_url_env = os.getenv('PROXY_URL', None)
    proxy_url = proxy_url_env if proxy_url_env else proxy_url_config

    proxies = {'http': proxy_url, 'https': proxy_url} if use_proxy and proxy_url else None
    requests_params = {'proxies': proxies} if proxies else None

    if use_proxy and not proxy_url:
        logger.warning("é…ç½®ä¸ºä½¿ç”¨ä»£ç†ï¼Œä½†æœªæä¾›ä»£ç† URLã€‚")
    elif use_proxy:
        logger.info(f"ä½¿ç”¨ä»£ç†æœåŠ¡å™¨: {proxy_url}")

    # 3. åˆå§‹åŒ– Binance Client (ä½¿ç”¨ä» st.secrets è·å–çš„å¯†é’¥)
    binance_client = Client(api_key=api_key, api_secret=api_secret, requests_params=requests_params)
    binance_client.ping() # æµ‹è¯•è¿æ¥
    server_time = binance_client.get_server_time()
    logger.info(f"æˆåŠŸä½¿ç”¨ Streamlit Secrets ä¸­çš„å¯†é’¥è¿æ¥åˆ°å¸å®‰æœåŠ¡å™¨ï¼ŒæœåŠ¡å™¨æ—¶é—´: {datetime.fromtimestamp(server_time['serverTime']/1000)}")

    # 4. ç§»é™¤ DataFetcher å’Œ KlineAnalysisModule çš„å®ä¾‹åŒ– (ä¿æŒä¸å˜)
    logger.info("æ ¸å¿ƒæ¨¡å—æ£€æŸ¥å’Œå¸å®‰è¿æ¥æµ‹è¯•å®Œæˆã€‚æˆäº¤æµåˆ†ææ¨¡å—å·²å¯¼å…¥ã€‚")

# ç§»é™¤å¯¹é…ç½®æ¨¡å— Attribute Error çš„æ•è·ï¼Œå› ä¸ºå¯†é’¥ä¸å†ä»é‚£é‡Œè¯»å–
# except AttributeError as e:
#     st.error(f"é…ç½®æ¨¡å— 'é…ç½®.py' ä¸­ç¼ºå°‘å¿…è¦çš„é…ç½®é¡¹: {e}")
#     logger.error(f"è¯»å–é…ç½®é¡¹å¤±è´¥: {e}", exc_info=True)
#     st.stop()
except Exception as e:
    # é€šç”¨é”™è¯¯å¤„ç†ä¿æŒä¸å˜
    st.error(f"åˆå§‹åŒ–æˆ–è¿æ¥å¸å®‰æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    logger.error(f"åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
    st.stop()

# --- ç¼“å­˜çš„åˆ†æå‡½æ•° ---

# K çº¿åˆ†æç¼“å­˜å‡½æ•° (ä¿æŒä¸å˜ï¼Œé‡å‘½å session_state å˜é‡)
@st.cache_data(ttl=CACHE_TTL_SECONDS)
def get_manual_kline_analysis_cached(symbol: str, market_type: str, timeframes: tuple, cache_key_minute: str):
    logger.info(f"Kçº¿ç¼“å­˜æœªå‘½ä¸­æˆ–å·²è¿‡æœŸ (Key: {symbol}/{market_type}/{cache_key_minute})ã€‚æ‰§è¡ŒKçº¿åˆ†æ...")
    try:
        # è°ƒç”¨ kçº¿åˆ†ææ¨¡å—
        analysis_result_tuple = kline_analysis_module.åˆ†æKçº¿ç»“æ„ä¸å½¢æ€(
            symbol=symbol,
            market_type=market_type,
            timeframes=list(timeframes)
        )
        # ... (é”™è¯¯å¤„ç†å’Œæ—¥å¿—ä¿æŒä¸å˜) ...
        if isinstance(analysis_result_tuple, tuple) and len(analysis_result_tuple) > 0:
            analysis_result_dict = analysis_result_tuple[0]
            if not isinstance(analysis_result_dict, dict):
                err_msg = f"Kçº¿åˆ†æå‡½æ•°å†…éƒ¨é”™è¯¯: è¿”å›çš„ç¬¬ä¸€ä¸ªå…ƒç´ ä¸æ˜¯å­—å…¸ (ç±»å‹: {type(analysis_result_dict)})"
                logger.error(err_msg)
                return {"error": err_msg}
            logger.info(f"Kçº¿åˆ†ææˆåŠŸå®Œæˆï¼Œè¿”å›å­—å…¸çš„é”®: {list(analysis_result_dict.keys())}")
            return analysis_result_dict
        else:
            err_msg = f"Kçº¿åˆ†æå‡½æ•°å†…éƒ¨é”™è¯¯: è¿”å›æ ¼å¼éé¢„æœŸ tuple (ç±»å‹: {type(analysis_result_tuple)}, å€¼: {repr(analysis_result_tuple)[:100]}...)"
            logger.error(err_msg)
            return {"error": err_msg}
    except Exception as e:
        err_msg = f"Kçº¿åˆ†ææ‰§è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {type(e).__name__} - {repr(e)}"
        logger.error(f"æ‰§è¡Œç¼“å­˜Kçº¿åˆ†æ {symbol} ({market_type}) æ—¶æ•è·åˆ°å¼‚å¸¸: {repr(e)}", exc_info=True)
        return {"error": err_msg}

# æ–°å¢ï¼šæˆäº¤æµåˆ†æç¼“å­˜å‡½æ•°
@st.cache_data(ttl=CACHE_TTL_SECONDS)
def get_manual_volume_analysis_cached(symbol: str, market_type: str, cache_key_minute: str):
    """
    å¸¦ç¼“å­˜çš„æˆäº¤æµæ‰‹åŠ¨åˆ†æå‡½æ•°ã€‚
    è°ƒç”¨ æˆäº¤æµç½‘é¡µåˆ†æ.åˆ†ææˆäº¤æµ(symbol, market_type)ï¼Œä½¿ç”¨æ¨¡å—å†…çš„é»˜è®¤å‚æ•°ã€‚
    """
    # ç§»é™¤ timeframes å‚æ•°ï¼Œæ›´æ–°æ—¥å¿—ä¿¡æ¯
    logger.info(f"æˆäº¤é‡ç¼“å­˜æœªå‘½ä¸­æˆ–å·²è¿‡æœŸ (Key: {symbol}/{market_type}/{cache_key_minute})ã€‚æ‰§è¡Œæˆäº¤é‡åˆ†æ (ä½¿ç”¨é»˜è®¤limit)...")
    try:
        # è°ƒç”¨ æˆäº¤æµåˆ†æ æ¨¡å—çš„å‡½æ•°ï¼Œå‡½æ•°åæ”¹ä¸º åˆ†ææˆäº¤æµ
        # ä¸å†ä¼ é€’ timeframesï¼Œè®©å‡½æ•°ä½¿ç”¨é»˜è®¤ limit æˆ– time_windows
        analysis_result = æˆäº¤æµç½‘é¡µåˆ†æ.åˆ†ææˆäº¤æµ(
            symbol=symbol,
            market_type=market_type
            # å‡è®¾å‡½æ•°å†…éƒ¨æœ‰é»˜è®¤ limit æˆ– time_windows
        )

        # å‡è®¾è¿”å›çš„æ˜¯ä¸€ä¸ªå­—å…¸ (åç»­é€»è¾‘ä¸å˜)
        if isinstance(analysis_result, dict):
            logger.info(f"æˆäº¤é‡åˆ†ææˆåŠŸå®Œæˆï¼Œè¿”å›å­—å…¸çš„é”®: {list(analysis_result.keys())}")
            return analysis_result
        else:
            err_msg = f"æˆäº¤é‡åˆ†æå‡½æ•°è¿”å›æ ¼å¼æœªçŸ¥æˆ–éé¢„æœŸ: {type(analysis_result)}ã€‚è¯·æ£€æŸ¥ 'æˆäº¤æµåˆ†æ.py'ã€‚"
            logger.error(err_msg + f" è¿”å›å†…å®¹ (å‰100å­—ç¬¦): {repr(analysis_result)[:100]}...")
            return {"raw_result": analysis_result, "warning": err_msg}

    except AttributeError:
         # æ›´æ–°é”™è¯¯ä¿¡æ¯ï¼Œå‡½æ•°åå·²æ”¹ä¸º åˆ†ææˆäº¤æµ
         err_msg = f"æ— æ³•åœ¨ 'æˆäº¤æµåˆ†æ.py' æ¨¡å—ä¸­æ‰¾åˆ°åä¸º 'åˆ†ææˆäº¤æµ' çš„å‡½æ•°ã€‚è¯·æ£€æŸ¥æ¨¡å—å®ç°ã€‚"
         logger.error(err_msg, exc_info=True)
         return {"error": err_msg}
    except Exception as e:
        err_msg = f"æˆäº¤é‡åˆ†ææ‰§è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {type(e).__name__} - {repr(e)}"
        logger.error(f"æ‰§è¡Œç¼“å­˜æˆäº¤é‡åˆ†æ {symbol} ({market_type}) æ—¶æ•è·åˆ°å¼‚å¸¸: {repr(e)}", exc_info=True)
        return {"error": err_msg}

# --- Streamlit åº”ç”¨ç•Œé¢ ---
st.set_page_config(page_title="Kçº¿ä¸æˆäº¤æµåˆ†æ", layout="wide") # ä¿®æ”¹é¡µé¢æ ‡é¢˜
st.title("ğŸ“ˆ Kçº¿ä¸æˆäº¤æµåˆ†æå·¥å…·") # ä¿®æ”¹åº”ç”¨æ ‡é¢˜

# åˆ›å»ºå››ä¸ª Tab é¡µ
tab_kline_manual, tab_kline_auto, tab_volume_manual, tab_volume_auto = st.tabs([
    "ğŸ” Kçº¿æ‰‹åŠ¨åˆ†æ",
    "â±ï¸ Kçº¿è‡ªåŠ¨æŠ¥å‘Š",
    "ğŸ“Š æˆäº¤æµæ‰‹åŠ¨åˆ†æ",
    "â±ï¸ æˆäº¤æµè‡ªåŠ¨æŠ¥å‘Š"
])

# --- Kçº¿æ‰‹åŠ¨åˆ†ææ ‡ç­¾é¡µ (åŸºæœ¬ä¿æŒä¸å˜ï¼Œä¿®æ”¹ session_state å˜é‡å) ---
with tab_kline_manual:
    st.header("æ‰‹åŠ¨è§¦å‘å•å¸ç§ K çº¿åˆ†æ")
    st.markdown(f"åˆ†æç»“æœå°†åœ¨ **{CACHE_TTL_SECONDS}ç§’** å†…ä¸ºç›¸åŒå‚æ•°ç¼“å­˜ã€‚")

    POPULAR_SYMBOLS = ["BTCUSDT", "ETHUSDT", "BNBUSDT", "SOLUSDT", "DOGEUSDT", "XRPUSDT", "ADAUSDT", "LINKUSDT", "MATICUSDT", "DOTUSDT"]
    SELECTBOX_PLACEHOLDER = "--- æˆ–é€‰æ‹©å¸¸ç”¨äº¤æ˜“å¯¹ ---"

    col1_km, col2_km = st.columns([2, 1])
    with col1_km:
        symbol_input_km = st.text_input("è¾“å…¥äº¤æ˜“å¯¹ (ä¾‹å¦‚ BTCUSDT):", "", key="kline_manual_symbol_input").upper()
        symbol_selected_km = st.selectbox("æˆ–é€‰æ‹©å¸¸ç”¨äº¤æ˜“å¯¹:",
                                       options=[SELECTBOX_PLACEHOLDER] + sorted(POPULAR_SYMBOLS),
                                       index=0,
                                       key="kline_manual_symbol_select")
    with col2_km:
        market_type_options_km = {'Uæœ¬ä½åˆçº¦': 'futures', 'ç°è´§': 'spot'}
        selected_mt_display_km = st.selectbox("é€‰æ‹©å¸‚åœºç±»å‹:", list(market_type_options_km.keys()), key="kline_manual_market_type")
        market_type_km = market_type_options_km[selected_mt_display_km]

    available_timeframes_km = ["1m", "3m", "5m", "15m", "30m", "1h", "2h", "4h", "6h", "8h", "12h", "1d", "3d", "1w", "1M"]
    default_timeframes_km = ["3m", "5m", "15m", "1h", "4h", "1d"]
    selected_timeframes_km = st.multiselect("é€‰æ‹©è¦åˆ†æçš„æ—¶é—´å‘¨æœŸ:", available_timeframes_km, default=default_timeframes_km, key="kline_manual_timeframes")

    analyze_button_km = st.button("å¼€å§‹ K çº¿åˆ†æ", key="kline_manual_analyze_button")

    symbol_to_analyze_km = None
    if analyze_button_km:
        if symbol_selected_km != SELECTBOX_PLACEHOLDER:
            symbol_to_analyze_km = symbol_selected_km
        elif symbol_input_km:
            symbol_to_analyze_km = symbol_input_km

        if not symbol_to_analyze_km:
            st.warning("è¯·è¾“å…¥æˆ–é€‰æ‹©ä¸€ä¸ªäº¤æ˜“å¯¹ã€‚")
        elif not selected_timeframes_km:
            st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ—¶é—´å‘¨æœŸã€‚")
        else:
            current_minute_str_km = datetime.now().strftime("%Y-%m-%d %H:%M")
            timeframes_tuple_km = tuple(sorted(selected_timeframes_km))

            with st.spinner(f"æ­£åœ¨åˆ†æ K çº¿ {symbol_to_analyze_km} ({market_type_km}) æ—¶é—´å‘¨æœŸ: {', '.join(selected_timeframes_km)}..."):
                # è°ƒç”¨å¸¦ç¼“å­˜çš„å‡½æ•°ï¼Œç»“æœå­˜å…¥ manual_kline_analysis_result
                st.session_state.manual_kline_analysis_result = get_manual_kline_analysis_cached(
                    symbol_to_analyze_km,
                    market_type_km,
                    timeframes_tuple_km,
                    current_minute_str_km
                )
                # æ›´æ–°ç”¨äºæ˜¾ç¤ºçš„å˜é‡ (å¦‚æœåˆ†ææˆåŠŸå¯åŠ¨)
                st.session_state.last_analyzed_symbol = symbol_to_analyze_km
                st.session_state.last_analyzed_market = selected_mt_display_km

    # æ˜¾ç¤º K çº¿æ‰‹åŠ¨åˆ†æç»“æœ (ä¿æŒä¸å˜ï¼Œè¯»å– session_state.manual_kline_analysis_result)
    manual_kline_result_placeholder = st.empty()

    logger.debug(f"å‡†å¤‡æ˜¾ç¤ºæ‰‹åŠ¨ K çº¿ç»“æœã€‚Session state å†…å®¹: {st.session_state.get('manual_kline_analysis_result')}")

    if st.session_state.manual_kline_analysis_result:
        result_dict_km = st.session_state.manual_kline_analysis_result
        display_symbol_km = st.session_state.get('last_analyzed_symbol', 'æœªçŸ¥å¸ç§')
        display_market_km = st.session_state.get('last_analyzed_market', 'æœªçŸ¥å¸‚åœº')

        with manual_kline_result_placeholder.container():
            st.markdown("---")
            st.subheader(f"K çº¿åˆ†æç»“æœ: {display_symbol_km} ({display_market_km})")

            if isinstance(result_dict_km, dict) and 'error' in result_dict_km and result_dict_km['error'] is not None:
                logger.error(f"æ˜¾ç¤º K çº¿åˆ†æå¤±è´¥ç»“æœ: {result_dict_km['error']}")
                st.error(f"K çº¿åˆ†æå¤±è´¥: {result_dict_km['error']}")
            elif isinstance(result_dict_km, dict) and 'confluence_summary' in result_dict_km and 'timeframe_analysis' in result_dict_km:
                logger.info("æ˜¾ç¤ºæœ‰æ•ˆçš„ K çº¿æ‰‹åŠ¨åˆ†æç»“æœã€‚")
                # ... (è¿™é‡Œçœç•¥äº†æ˜¾ç¤º K çº¿ç»“æœçš„è¯¦ç»†ä»£ç ï¼Œä¿æŒå’Œä¹‹å‰ä¸€è‡´) ...
                # --- æ€»ç»“æ˜¾ç¤º ---
                summary_km = result_dict_km['confluence_summary']
                details_km = result_dict_km['timeframe_analysis']
                st.subheader("Kçº¿ååŒåˆ†ææ€»ç»“:")
                col1_km_res, col2_km_res, col3_km_res, col4_km_res = st.columns(4)
                col1_km_res.metric("åå‘ (Bias)", summary_km.get('bias', 'N/A'))
                col2_km_res.metric("ç½®ä¿¡åº¦ (Confidence)", summary_km.get('confidence', 'N/A'))
                score_km = summary_km.get('weighted_score', 'N/A')
                score_display_km = f"{score_km:.1f}" if isinstance(score_km, (int, float)) else 'N/A'
                col3_km_res.metric("åŠ æƒåˆ†æ•° (Score)", score_display_km)
                current_price_km = result_dict_km.get('last_price', 'N/A')
                price_display_km = 'N/A'
                # (ä»·æ ¼æ ¼å¼åŒ–é€»è¾‘)
                if isinstance(current_price_km, (int, float)):
                    if current_price_km > 1000: price_display_km = f"{current_price_km:.2f}"
                    elif current_price_km > 1: price_display_km = f"{current_price_km:.4f}"
                    else: price_display_km = f"{current_price_km:.6f}"
                elif isinstance(current_price_km, str):
                    try:
                        price_float_km = float(current_price_km)
                        if price_float_km > 1000: price_display_km = f"{price_float_km:.2f}"
                        elif price_float_km > 1: price_display_km = f"{price_float_km:.4f}"
                        else: price_display_km = f"{price_float_km:.6f}"
                    except (ValueError, TypeError): price_display_km = current_price_km
                else: price_display_km = str(current_price_km)
                col4_km_res.metric("å½“å‰ä»·æ ¼", price_display_km)
                if summary_km.get('reasoning'):
                    st.markdown("**ä¸»è¦ç†ç”±:**")
                    reasoning_text_km = "\n".join([f"- {reason}" for reason in summary_km['reasoning']])
                    st.markdown(reasoning_text_km)
                if summary_km.get('warnings'):
                    st.markdown("**æ³¨æ„:**")
                    for warning in summary_km['warnings']: st.warning(warning)
                st.divider()
                # --- å…³é”®ä¿¡å·è¡¨ ---
                st.subheader("å„å‘¨æœŸå…³é”®ä¿¡å·:")
                # ... (çœç•¥ K çº¿ä¿¡å·è¡¨ä»£ç ) ...
                key_signals_data_km = []
                if isinstance(details_km, dict):
                    try:
                        def sort_key_km(tf): num = int(tf[:-1]); unit = tf[-1]; unit_map = {'m': 1, 'h': 60, 'd': 1440, 'w': 10080, 'M': 43200}; return unit_map.get(unit, 0) * num
                        sorted_timeframes_for_table_km = sorted(details_km.keys(), key=sort_key_km)
                    except Exception: sorted_timeframes_for_table_km = list(details_km.keys())
                    for tf_km in sorted_timeframes_for_table_km:
                         if tf_km in details_km:
                             tf_data_km = details_km[tf_km]
                             if isinstance(tf_data_km, dict):
                                 # (çœç•¥ Kçº¿ä¿¡å·è¡¨è¡Œæ•°æ®æå–ä»£ç )
                                 row_data_km = {"å‘¨æœŸ": tf_km}
                                 row_data_km["MAè¶‹åŠ¿"] = tf_data_km.get('trend_ma', '-')
                                 macd_data_km = tf_data_km.get('trend_macd', {}); row_data_km["MACDæ–¹å‘"] = macd_data_km.get('status', '-')
                                 macd_hist_str_km = macd_data_km.get('histogram'); macd_momentum_km = '-'
                                 try:
                                     if macd_hist_str_km is not None: macd_hist_float_km = float(macd_hist_str_km); macd_momentum_km = "æ­£å‘" if macd_hist_float_km > 0 else ("è´Ÿå‘" if macd_hist_float_km < 0 else "é›¶è½´")
                                 except (ValueError, TypeError): pass
                                 row_data_km["MACDåŠ¨é‡"] = macd_momentum_km
                                 dmi_data_km = tf_data_km.get('trend_dmi', {}); dmi_status_km = dmi_data_km.get('status', '-'); dmi_strength_km = dmi_data_km.get('strength', '-'); row_data_km["DMIæ–¹å‘"] = f"{dmi_status_km}, {dmi_strength_km}" if dmi_status_km != '-' and dmi_strength_km != '-' else (dmi_status_km if dmi_status_km != '-' else dmi_strength_km)
                                 adx_value_str_km = dmi_data_km.get('ADX'); adx_display_km = '-'
                                 try:
                                     if adx_value_str_km is not None: adx_value_float_km = float(adx_value_str_km); adx_display_km = f"{adx_value_float_km:.1f}"
                                 except (ValueError, TypeError): adx_display_km = str(adx_value_str_km) if adx_value_str_km else '-'
                                 row_data_km["ADX"] = adx_display_km
                                 vol_data_km = tf_data_km.get('volatility', {}); row_data_km["æ³¢åŠ¨çŠ¶æ€"] = vol_data_km.get('status', '-')
                                 atr_value_str_km = vol_data_km.get('atr'); atr_display_km = '-'
                                 try:
                                     if atr_value_str_km is not None: atr_value_float_km = float(atr_value_str_km); atr_display_km = f"{atr_value_float_km:.2f}"
                                 except (ValueError, TypeError): atr_display_km = str(atr_value_str_km) if atr_value_str_km else '-'
                                 row_data_km["ATR"] = atr_display_km
                                 pp_value_str_km = tf_data_km.get('pivot_point'); pp_display_km = '-'
                                 try:
                                     if pp_value_str_km is not None: pp_value_float_km = float(pp_value_str_km); pp_display_km = f"{pp_value_float_km:.2f}"
                                 except (ValueError, TypeError): pp_display_km = str(pp_value_str_km) if pp_value_str_km else '-'
                                 row_data_km["æ¢è½´ç‚¹(PP)"] = pp_display_km
                                 patterns_km = tf_data_km.get('patterns', []); pattern_display_km = patterns_km[0].get('name', '-') if patterns_km else "-"; pattern_implication_km = f" ({patterns_km[0].get('implication', '?')})" if patterns_km else ""; row_data_km["ä¸»è¦å½¢æ€"] = f"{pattern_display_km}{pattern_implication_km}".strip()
                                 key_signals_data_km.append(row_data_km)
                if key_signals_data_km:
                    key_signals_df_km = pd.DataFrame(key_signals_data_km)
                    display_columns_km = ["å‘¨æœŸ", "MAè¶‹åŠ¿", "MACDæ–¹å‘", "MACDåŠ¨é‡", "DMIæ–¹å‘", "ADX", "æ³¢åŠ¨çŠ¶æ€", "ATR", "æ¢è½´ç‚¹(PP)", "ä¸»è¦å½¢æ€"]
                    valid_columns_km = [col for col in display_columns_km if col in key_signals_df_km.columns]
                    st.dataframe(key_signals_df_km[valid_columns_km], use_container_width=True, hide_index=True)
                else: st.info("æœªèƒ½æå–Kçº¿å…³é”®ä¿¡å·æ•°æ®ä»¥ç”Ÿæˆæ‘˜è¦è¡¨ã€‚")
                st.divider()
                # --- Kçº¿å‘¨æœŸè¯¦æƒ… (ä¸æŠ˜å ) ---
                st.subheader("å„å‘¨æœŸè¯¦ç»†åˆ†æ:")
                if isinstance(details_km, dict):
                     # ... (çœç•¥ K çº¿å‘¨æœŸè¯¦æƒ…æ˜¾ç¤ºä»£ç ) ...
                    try:
                        def sort_key_exp_km(tf): num = int(tf[:-1]); unit = tf[-1]; unit_map = {'m': 1, 'h': 60, 'd': 1440, 'w': 10080, 'M': 43200}; return unit_map.get(unit, 0) * num
                        sorted_timeframes_exp_km = sorted(details_km.keys(), key=sort_key_exp_km)
                    except Exception: sorted_timeframes_exp_km = list(details_km.keys())
                    for tf_km_exp in sorted_timeframes_exp_km:
                         if tf_km_exp in details_km:
                             tf_data_km_exp = details_km[tf_km_exp]
                             st.subheader(f"{tf_km_exp} å‘¨æœŸ")
                             if isinstance(tf_data_km_exp, dict):
                                 col1_exp_km, col2_exp_km, col3_exp_km = st.columns(3)
                                 with col1_exp_km: # MA & MACD
                                      st.markdown("**MA & MACD**")
                                      st.markdown(f"- **è¶‹åŠ¿:** {tf_data_km_exp.get('trend_ma', '-')}")
                                      macd_data_km_exp = tf_data_km_exp.get('trend_macd', {}); macd_direction_km_exp = macd_data_km_exp.get('status', '-'); macd_hist_str_km_exp = macd_data_km_exp.get('histogram'); macd_momentum_km_exp = '-'
                                      try:
                                           if macd_hist_str_km_exp is not None: macd_hist_float_km_exp = float(macd_hist_str_km_exp); macd_momentum_km_exp = "æ­£å‘" if macd_hist_float_km_exp > 0 else ("è´Ÿå‘" if macd_hist_float_km_exp < 0 else "é›¶è½´")
                                      except (ValueError, TypeError): pass
                                      st.markdown(f"- **æ–¹å‘:** {macd_direction_km_exp}")
                                      st.markdown(f"- **åŠ¨é‡:** {macd_momentum_km_exp}")
                                 with col2_exp_km: # DMI & æ³¢åŠ¨ç‡
                                      st.markdown("**DMI & æ³¢åŠ¨ç‡**")
                                      dmi_data_km_exp = tf_data_km_exp.get('trend_dmi', {}); dmi_status_km_exp = dmi_data_km_exp.get('status', '-'); dmi_strength_km_exp = dmi_data_km_exp.get('strength', '-'); dmi_display_km_exp = f"{dmi_status_km_exp}, {dmi_strength_km_exp}" if dmi_status_km_exp != '-' and dmi_strength_km_exp != '-' else (dmi_status_km_exp if dmi_status_km_exp != '-' else dmi_strength_km_exp); adx_value_str_km_exp = dmi_data_km_exp.get('ADX'); adx_display_km_exp = '-'
                                      try:
                                           if adx_value_str_km_exp is not None: adx_value_float_km_exp = float(adx_value_str_km_exp); adx_display_km_exp = f"{adx_value_float_km_exp:.1f}"
                                      except (ValueError, TypeError): adx_display_km_exp = str(adx_value_str_km_exp) if adx_value_str_km_exp else '-'
                                      st.markdown(f"- **æ–¹å‘:** {dmi_display_km_exp}")
                                      st.markdown(f"- **ADX:** {adx_display_km_exp}")
                                      vol_data_km_exp = tf_data_km_exp.get('volatility', {}); st.markdown(f"- **çŠ¶æ€:** {vol_data_km_exp.get('status', '-')}")
                                 with col3_exp_km: # ATR, PP & å½¢æ€
                                      st.markdown("**ATR, PP & å½¢æ€**")
                                      vol_data_km_exp_atr = tf_data_km_exp.get('volatility', {}); atr_value_str_km_exp = vol_data_km_exp_atr.get('atr'); atr_display_km_exp_atr = '-'
                                      try:
                                           if atr_value_str_km_exp is not None: atr_value_float_km_exp = float(atr_value_str_km_exp); atr_display_km_exp_atr = f"{atr_value_float_km_exp:.2f}"
                                      except (ValueError, TypeError): atr_display_km_exp_atr = str(atr_value_str_km_exp) if atr_value_str_km_exp else '-'
                                      st.markdown(f"- **ATR:** {atr_display_km_exp_atr}")
                                      pp_value_str_km_exp = tf_data_km_exp.get('pivot_point'); pp_display_km_exp = '-'
                                      try:
                                           if pp_value_str_km_exp is not None: pp_value_float_km_exp = float(pp_value_str_km_exp); pp_display_km_exp = f"{pp_value_float_km_exp:.2f}"
                                      except (ValueError, TypeError): pp_display_km_exp = str(pp_value_str_km_exp) if pp_value_str_km_exp else '-'
                                      st.markdown(f"- **PP:** {pp_display_km_exp}")
                                      patterns_km_exp = tf_data_km_exp.get('patterns', []); st.markdown("**å½¢æ€:**")
                                      if patterns_km_exp:
                                           for p_km in patterns_km_exp: st.markdown(f"  - {p_km.get('name', 'æœªçŸ¥')}")
                                      else: st.markdown("  - æ— ")
                             else: st.write(tf_data_km_exp)
                             st.divider()
                         else: st.warning("Kçº¿æ—¶é—´å‘¨æœŸè¯¦ç»†æ•°æ®æ ¼å¼é”™è¯¯ã€‚")
                         st.divider()
                         # --- Kçº¿åŸå§‹ JSON (ä¸æŠ˜å ) ---
                         st.subheader("åŸå§‹Kçº¿JSONæ•°æ®:")
                         st.json(result_dict_km)
                    else:
                         st.warning("K çº¿åˆ†ææ•°æ®ä¸å®Œæ•´æˆ–æ ¼å¼é”™è¯¯ã€‚")
                         st.subheader("åŸå§‹Kçº¿JSONæ•°æ®:")
                         st.json(result_dict_km)
            elif isinstance(result_dict_km, dict) and (explicit_error_ka_detail := result_dict_km.get('error')):
                 # æ˜¾ç¤ºé”™è¯¯ï¼Œä½†ä¸ä½¿ç”¨ expander
                 st.error(f"åˆ†æ {symbol_km_detail} æ—¶å‡ºé”™: {explicit_error_ka_detail}")
                 tb_ka = result_dict_km.get('traceback')
                 if tb_ka:
                     with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ… (Traceback)", expanded=False):
                          st.code(tb_ka, language='python')

# --- Kçº¿è‡ªåŠ¨æŠ¥å‘Šæ ‡ç­¾é¡µ (åŸºæœ¬ä¿æŒä¸å˜ï¼Œä¿®æ”¹æ–‡ä»¶åå¸¸é‡) ---
with tab_kline_auto:
    st.header(f"K çº¿è‡ªåŠ¨åˆ†ææŠ¥å‘Š (Top {TOP_N_SYMBOLS} äº¤æ˜“é‡)")
    st.markdown(f"**é‡è¦æç¤º:** æ­¤åŠŸèƒ½ä¾èµ–ä¸€ä¸ªç‹¬ç«‹çš„**åå° K çº¿åˆ†æè„šæœ¬**æ¯ {AUTO_ANALYSIS_INTERVAL_MINUTES} åˆ†é’Ÿè¿è¡Œä¸€æ¬¡ï¼Œå¹¶å°†ç»“æœå†™å…¥ `{AUTO_KLINE_RESULTS_FILE}` æ–‡ä»¶ã€‚") # ä½¿ç”¨æ–°å¸¸é‡
    st.markdown("è¯·ç¡®ä¿è¯¥åå°è„šæœ¬å·²æ­£ç¡®é…ç½®å¹¶æ­£åœ¨è¿è¡Œã€‚")

    if st.button("æ‰‹åŠ¨åˆ·æ–° K çº¿æŠ¥å‘Š", key="kline_auto_refresh_button"):
        st.rerun()

    auto_kline_results_data = None
    last_kline_update_time_str = "æœªçŸ¥"
    kline_file_error = None

    if os.path.exists(AUTO_KLINE_RESULTS_FILE): # ä½¿ç”¨æ–°å¸¸é‡
        try:
            kline_file_mod_time = os.path.getmtime(AUTO_KLINE_RESULTS_FILE)
            last_kline_update_time = datetime.fromtimestamp(kline_file_mod_time)
            if datetime.now() - last_kline_update_time > timedelta(minutes=AUTO_ANALYSIS_INTERVAL_MINUTES * 3):
                 st.warning(f"K çº¿ç»“æœæ–‡ä»¶ `{AUTO_KLINE_RESULTS_FILE}` æœ€åæ›´æ–°äº {last_kline_update_time.strftime('%Y-%m-%d %H:%M:%S')}ï¼Œå¯èƒ½å·²è¿‡æœŸã€‚")
            last_kline_update_time_str = last_kline_update_time.strftime('%Y-%m-%d %H:%M:%S')
            with open(AUTO_KLINE_RESULTS_FILE, 'r', encoding='utf-8') as f:
                auto_kline_results_data = json.load(f)
        except json.JSONDecodeError as e:
            kline_file_error = f"è¯»å– K çº¿ç»“æœæ–‡ä»¶ `{AUTO_KLINE_RESULTS_FILE}` æ—¶ JSON è§£æå¤±è´¥: {e}"
            logger.error(kline_file_error)
        except Exception as e:
            kline_file_error = f"è¯»å– K çº¿ç»“æœæ–‡ä»¶ `{AUTO_KLINE_RESULTS_FILE}` æ—¶å‘ç”Ÿé”™è¯¯: {e}"
            logger.error(kline_file_error, exc_info=True)
    else:
        kline_file_error = f"K çº¿ç»“æœæ–‡ä»¶ `{AUTO_KLINE_RESULTS_FILE}` ä¸å­˜åœ¨ã€‚è¯·å¯åŠ¨åå° K çº¿åˆ†æè„šæœ¬ã€‚"

    st.caption(f"K çº¿æŠ¥å‘Šæ•°æ®æœ€åæ›´æ–°æ—¶é—´: {last_kline_update_time_str}")

    if kline_file_error:
        st.error(kline_file_error)
    elif not auto_kline_results_data or not isinstance(auto_kline_results_data, dict):
         st.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ K çº¿è‡ªåŠ¨åˆ†æç»“æœæˆ–ç»“æœæ ¼å¼ä¸æ­£ç¡®ã€‚")
         logger.warning(f"K çº¿è‡ªåŠ¨åˆ†æç»“æœæ–‡ä»¶å†…å®¹æ— æ•ˆæˆ–éå­—å…¸: {type(auto_kline_results_data)}")
    else:
        # K çº¿æ‘˜è¦è¡¨é€»è¾‘ (ä¿æŒä¸å˜)
        summary_kline_data_list = []
        failed_kline_symbols = []
        # ... (çœç•¥ K çº¿æ‘˜è¦æ•°æ®å‡†å¤‡ä»£ç ) ...
        logger.info("å¼€å§‹ä¸º K çº¿è‡ªåŠ¨æŠ¥å‘Šå‡†å¤‡æ‘˜è¦æ•°æ®...")
        for symbol_ka, result_dict_ka in auto_kline_results_data.items():
             if isinstance(result_dict_ka, dict):
                 explicit_error_ka = result_dict_ka.get('error')
                 if explicit_error_ka is None and 'confluence_summary' in result_dict_ka and isinstance(result_dict_ka['confluence_summary'], dict):
                     summary_ka = result_dict_ka['confluence_summary']
                     bias_ka = summary_ka.get('bias', 'N/A')
                     confidence_ka = summary_ka.get('confidence', 'N/A')
                     score_ka = summary_ka.get('weighted_score', 'N/A')
                     score_display_ka = f"{score_ka:.1f}" if isinstance(score_ka, (int, float)) else str(score_ka)
                     current_price_ka = result_dict_ka.get('last_price', 'N/A')
                     price_display_ka = 'N/A'
                     # (ä»·æ ¼æ ¼å¼åŒ–é€»è¾‘)
                     if isinstance(current_price_ka, (int, float)):
                         if current_price_ka > 1000: price_display_ka = f"{current_price_ka:.2f}"
                         elif current_price_ka > 1: price_display_ka = f"{current_price_ka:.4f}"
                         else: price_display_ka = f"{current_price_ka:.6f}"
                     elif isinstance(current_price_ka, str):
                         try:
                             price_float_ka = float(current_price_ka)
                             if price_float_ka > 1000: price_display_ka = f"{price_float_ka:.2f}"
                             elif price_float_ka > 1: price_display_ka = f"{price_float_ka:.4f}"
                             else: price_display_ka = f"{price_float_ka:.6f}"
                         except (ValueError, TypeError): price_display_ka = current_price_ka
                     else: price_display_ka = str(current_price_ka)
                     summary_kline_data_list.append({
                         "äº¤æ˜“å¯¹": symbol_ka,
                         "åå‘": bias_ka,
                         "ç½®ä¿¡åº¦": confidence_ka,
                         "åˆ†æ•°": score_display_ka,
                         "æœ€è¿‘ä»·æ ¼": price_display_ka,
                         "åŸå§‹åˆ†æ•°": score_ka if isinstance(score_ka, (int, float)) else -999
                     })
                 else:
                     failed_kline_symbols.append(symbol_ka)
             else:
                 failed_kline_symbols.append(symbol_ka)
        logger.info(f"K çº¿æ‘˜è¦æ•°æ®å‡†å¤‡å®Œæˆã€‚æˆåŠŸ: {len(summary_kline_data_list)}, å¤±è´¥/è·³è¿‡: {len(failed_kline_symbols)}.")

        st.markdown("---")
        st.subheader("ğŸ“ˆ K çº¿è‡ªåŠ¨åˆ†ææ‘˜è¦")
        if summary_kline_data_list:
            summary_kline_df = pd.DataFrame(summary_kline_data_list)
            # å¯ä»¥æ·»åŠ æ’åºå’Œæ ·å¼
            st.dataframe(summary_kline_df, use_container_width=True, hide_index=True)
        else:
            st.info("å½“å‰æ²¡æœ‰å¯ç”¨çš„ K çº¿æˆåŠŸåˆ†ææ‘˜è¦ã€‚")
        if failed_kline_symbols:
             st.caption(f"æ³¨æ„: ä»¥ä¸‹äº¤æ˜“å¯¹ K çº¿åˆ†æå¤±è´¥æˆ–æ•°æ®ä¸å®Œæ•´: {', '.join(failed_kline_symbols)}")

        # æˆäº¤æµè¯¦ç»†åˆ†æ (æŠ˜å ) é€»è¾‘ (å ä½ç¬¦)
        st.divider()
        st.subheader("ğŸ” å„äº¤æ˜“å¯¹ K çº¿è¯¦ç»†åˆ†æ")
        for symbol_ka_detail, result_dict_ka_detail in auto_kline_results_data.items():
            if symbol_ka_detail not in failed_kline_symbols and isinstance(result_dict_ka_detail, dict):
                with st.expander(f"**{symbol_ka_detail}** K çº¿è¯¦ç»†åˆ†æ", expanded=False):
                     # --- æ˜¾ç¤ºæˆäº¤é‡è¯¦æƒ… (éœ€è¦ä½ å®šä¹‰) ---
                     st.info(f"æ˜¾ç¤º {symbol_ka_detail} çš„ K çº¿è¯¦ç»†åˆ†æç»“æœã€‚")
                     # ç¤ºä¾‹ï¼šæ˜¾ç¤º confluence_summary
                     if 'confluence_summary' in result_dict_ka_detail:
                          st.write(result_dict_ka_detail['confluence_summary'])
                     # æ˜¾ç¤ºåŸå§‹ JSON
                     st.subheader("åŸå§‹ K çº¿ JSON æ•°æ®:")
                     st.json(result_dict_ka_detail)
                     # --- æ˜¾ç¤ºç»“æŸ ---
            elif isinstance(result_dict_ka_detail, dict) and (explicit_error_ka_detail := result_dict_ka_detail.get('error')):
                 st.error(f"åˆ†æ {symbol_ka_detail} æ—¶å‡ºé”™: {explicit_error_ka_detail}")
                 tb_ka = result_dict_ka_detail.get('traceback')
                 if tb_ka:
                     with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ… (Traceback)", expanded=False):
                          st.code(tb_ka, language='python')
        # --- å ä½ç¬¦ç»“æŸ ---


# --- æ–°å¢ï¼šæˆäº¤é‡æ‰‹åŠ¨åˆ†ææ ‡ç­¾é¡µ ---
with tab_volume_manual:
    st.header("æ‰‹åŠ¨è§¦å‘å•å¸ç§æˆäº¤æµåˆ†æ")
    st.markdown(f"åˆ†æç»“æœå°†åœ¨ **{CACHE_TTL_SECONDS}ç§’** å†…ä¸ºç›¸åŒå‚æ•°ç¼“å­˜ã€‚")

    # å¤ç”¨ K çº¿çš„å¸¸ç”¨å¸ç§åˆ—è¡¨å’Œå ä½ç¬¦
    POPULAR_SYMBOLS = ["BTCUSDT", "ETHUSDT", "BNBUSDT", "SOLUSDT", "DOGEUSDT", "XRPUSDT", "ADAUSDT", "LINKUSDT", "MATICUSDT", "DOTUSDT"]
    SELECTBOX_PLACEHOLDER = "--- æˆ–é€‰æ‹©å¸¸ç”¨äº¤æ˜“å¯¹ ---"

    col1_vm, col2_vm = st.columns([2, 1])
    with col1_vm:
        # ä½¿ç”¨ .get() å®‰å…¨åœ°è·å–ä¸Šæ¬¡ K çº¿åˆ†æçš„å¸ç§ä½œä¸ºé»˜è®¤å€¼
        last_k_symbol = st.session_state.get('last_analyzed_symbol')
        symbol_input_vm = st.text_input("è¾“å…¥äº¤æ˜“å¯¹ (ä¾‹å¦‚ BTCUSDT):", last_k_symbol if last_k_symbol else '', key="volume_manual_symbol_input").upper()
        
        # è®¡ç®— selectbox çš„é»˜è®¤ index æ—¶ï¼Œä¹Ÿè¦å®‰å…¨åœ°æ£€æŸ¥ last_k_symbol
        default_symbol_index_vm = 0 # é»˜è®¤ä¸ºå ä½ç¬¦
        if last_k_symbol and last_k_symbol in POPULAR_SYMBOLS:
            try:
                default_symbol_index_vm = POPULAR_SYMBOLS.index(last_k_symbol) + 1 # +1 å› ä¸º options é‡Œç¬¬ä¸€é¡¹æ˜¯å ä½ç¬¦
            except ValueError:
                 pass # å¦‚æœä¸åœ¨åˆ—è¡¨ä¸­ï¼Œä¿æŒé»˜è®¤å€¼

        symbol_selected_vm = st.selectbox("æˆ–é€‰æ‹©å¸¸ç”¨äº¤æ˜“å¯¹:",
                                       options=[SELECTBOX_PLACEHOLDER] + sorted(POPULAR_SYMBOLS),
                                       index=default_symbol_index_vm, # ä½¿ç”¨å®‰å…¨è®¡ç®—çš„ index
                                       key="volume_manual_symbol_select")
    with col2_vm:
        # ä½¿ç”¨ .get() å®‰å…¨åœ°è·å–ä¸Šæ¬¡ K çº¿åˆ†æçš„å¸‚åœºç±»å‹
        last_k_market = st.session_state.get('last_analyzed_market')
        market_type_options_vm = {'Uæœ¬ä½åˆçº¦': 'futures', 'ç°è´§': 'spot'}
        market_keys_list_vm = list(market_type_options_vm.keys())
        default_market_index_vm = 0
        if last_k_market and last_k_market in market_keys_list_vm:
             try:
                 default_market_index_vm = market_keys_list_vm.index(last_k_market)
             except ValueError:
                 pass # ä¿æŒé»˜è®¤
                 
        selected_mt_display_vm = st.selectbox("é€‰æ‹©å¸‚åœºç±»å‹:",
                                           market_keys_list_vm,
                                           index=default_market_index_vm, # ä½¿ç”¨å®‰å…¨è®¡ç®—çš„ index
                                           key="volume_manual_market_type")
        market_type_vm = market_type_options_vm[selected_mt_display_vm]

    analyze_button_vm = st.button("å¼€å§‹æˆäº¤æµåˆ†æ", key="volume_manual_analyze_button")

    symbol_to_analyze_vm = None
    if analyze_button_vm:
        if symbol_selected_vm != SELECTBOX_PLACEHOLDER:
            symbol_to_analyze_vm = symbol_selected_vm
        elif symbol_input_vm:
            symbol_to_analyze_vm = symbol_input_vm

        if not symbol_to_analyze_vm:
            st.warning("è¯·è¾“å…¥æˆ–é€‰æ‹©ä¸€ä¸ªäº¤æ˜“å¯¹ã€‚")
        # ç§»é™¤å¯¹ selected_timeframes_vm çš„æ£€æŸ¥
        # elif not selected_timeframes_vm: 
        #     st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ—¶é—´å‘¨æœŸã€‚")
        else:
            current_minute_str_vm = datetime.now().strftime("%Y-%m-%d %H:%M")
            # timeframes_tuple_vm = tuple(sorted(selected_timeframes_vm)) # ä¸å†éœ€è¦

            # æ›´æ–° spinner æç¤ºä¿¡æ¯
            with st.spinner(f"æ­£åœ¨åˆ†ææˆäº¤æµ {symbol_to_analyze_vm} ({market_type_vm})..."): 
                # è°ƒç”¨æˆäº¤é‡åˆ†æçš„ç¼“å­˜å‡½æ•°ï¼Œä¸å†ä¼ é€’ timeframes_tuple_vm
                st.session_state.manual_volume_analysis_result = get_manual_volume_analysis_cached(
                    symbol_to_analyze_vm,
                    market_type_vm,
                    # timeframes_tuple_vm, # ç§»é™¤
                    current_minute_str_vm
                )
                # æ›´æ–°ç”¨äºæ˜¾ç¤ºçš„å˜é‡ (ä¿æŒä¸å˜)
                st.session_state.last_analyzed_volume_symbol = symbol_to_analyze_vm
                st.session_state.last_analyzed_volume_market = selected_mt_display_vm

    # æ˜¾ç¤ºæˆäº¤é‡æ‰‹åŠ¨åˆ†æç»“æœ (å ä½ç¬¦é€»è¾‘)
    manual_volume_result_placeholder = st.empty()

    logger.debug(f"å‡†å¤‡æ˜¾ç¤ºæ‰‹åŠ¨æˆäº¤é‡ç»“æœã€‚Session state å†…å®¹: {st.session_state.get('manual_volume_analysis_result')}")

    if st.session_state.manual_volume_analysis_result:
        result_dict_vm = st.session_state.manual_volume_analysis_result
        display_symbol_vm = st.session_state.get('last_analyzed_volume_symbol', 'æœªçŸ¥å¸ç§')
        display_market_vm = st.session_state.get('last_analyzed_volume_market', 'æœªçŸ¥å¸‚åœº')

        with manual_volume_result_placeholder.container():
            st.markdown("---")
            st.subheader(f"æˆäº¤æµåˆ†æç»“æœ: {display_symbol_vm} ({display_market_vm})")

            if isinstance(result_dict_vm, dict) and result_dict_vm.get('error'): # æ£€æŸ¥ error é”®
                logger.error(f"æ˜¾ç¤ºæˆäº¤é‡åˆ†æå¤±è´¥ç»“æœ: {result_dict_vm['error']}")
                st.error(f"æˆäº¤é‡åˆ†æå¤±è´¥: {result_dict_vm['error']}")
            elif isinstance(result_dict_vm, dict):
                # --- æ ¹æ®å®é™…è¿”å›çš„ JSON ç»“æ„æ˜¾ç¤ºç»“æœ ---
                
                # --- 1. è¯„åˆ† & åˆ†æè¯¦æƒ… (ä¿æŒ) ---
                score_value = None
                try:
                    score_value = result_dict_vm.get('interpretation', {}).get('bias_score')
                except AttributeError as e:
                    logger.error(f"è®¿é—®è¯„åˆ† interpretation['bias_score'] æ—¶å‡ºé”™: {e}")
                if score_value is not None:
                    score_display = f"{score_value:.1f}" if isinstance(score_value, (int, float)) else str(score_value)
                    st.metric("è¯„åˆ† (Bias Score)", score_display)
                else:
                    st.metric("è¯„åˆ†", "N/A")
                    logger.warning(f"æœªèƒ½åœ¨ interpretation['bias_score'] æ‰¾åˆ°è¯„åˆ†ã€‚å®é™…é¡¶å±‚é”®: {list(result_dict_vm.keys())}")
                
                details_list = None
                try:
                    details_list = result_dict_vm.get('interpretation', {}).get('overall', {}).get('details')
                except AttributeError as e:
                    logger.error(f"è®¿é—®ç»†èŠ‚ interpretation['overall']['details'] æ—¶å‡ºé”™: {e}")
                if isinstance(details_list, list) and details_list:
                    st.subheader("åˆ†æè¯¦æƒ…:")
                    for item in details_list:
                        if isinstance(item, str):
                            cleaned_item = item.split(" : ", 1)[-1] if " : " in item else item
                            st.markdown(f"- {cleaned_item}")
                        else:
                            st.markdown(f"- {item}")
                else:
                    st.info("æœªæ‰¾åˆ°æœ‰æ•ˆçš„åˆ†æè¯¦æƒ…ã€‚")
                    logger.warning(f"æœªèƒ½åœ¨ interpretation['overall']['details'] æ‰¾åˆ°è¯¦æƒ…åˆ—è¡¨ã€‚å®é™…é¡¶å±‚é”®: {list(result_dict_vm.keys())}")
                st.divider()
                
                # --- 2. æ–°å¢ï¼šå…³é”®æŒ‡æ ‡å±•ç¤º (ä» overall æå–) ---
                st.subheader("å…³é”®æŒ‡æ ‡:")
                overall_metrics = result_dict_vm.get('overall', {}) # å®‰å…¨è·å– overall å­—å…¸
                
                col_m1, col_m2, col_m3 = st.columns(3)
                
                # Delta æˆäº¤é‡
                delta_vol = overall_metrics.get('delta_volume')
                delta_display = f"{delta_vol:,.2f}" if isinstance(delta_vol, (int, float)) else "N/A"
                col_m1.metric("Delta æˆäº¤é‡", delta_display)
                
                # ä¸»åŠ¨ä¹°å–é‡æ¯”
                taker_vol_ratio = overall_metrics.get('taker_volume_ratio')
                tvr_display = f"{taker_vol_ratio:.2f}" if isinstance(taker_vol_ratio, (int, float)) else "N/A"
                col_m2.metric("ä¸»åŠ¨ä¹°å–é‡æ¯” (ä¹°/å–)", tvr_display)

                # ä¸»åŠ¨ä¹°å–ç¬”æ•°æ¯”
                taker_trade_ratio = overall_metrics.get('taker_trade_ratio')
                ttr_display = f"{taker_trade_ratio:.2f}" if isinstance(taker_trade_ratio, (int, float)) else "N/A"
                col_m3.metric("ä¸»åŠ¨ä¹°å–ç¬”æ•°æ¯” (ä¹°/å–)", ttr_display)

                col_m4, col_m5, col_m6 = st.columns(3)

                # æ€»æˆäº¤é¢
                total_vol = overall_metrics.get('total_quote_volume')
                total_vol_display = f"{total_vol:,.2f}" if isinstance(total_vol, (int, float)) else "N/A"
                col_m4.metric("æ€»æˆäº¤é¢", total_vol_display)

                # æ¯ç§’æˆäº¤ç¬”æ•°
                trades_ps = overall_metrics.get('trades_per_second')
                tps_display = f"{trades_ps:.2f}" if isinstance(trades_ps, (int, float)) else "N/A"
                col_m5.metric("æ¯ç§’æˆäº¤ç¬”æ•°", tps_display)

                # å¹³å‡æ¯ç¬”æˆäº¤é¢
                avg_trade_size = overall_metrics.get('avg_trade_size_quote')
                avg_trade_display = f"{avg_trade_size:,.2f}" if isinstance(avg_trade_size, (int, float)) else "N/A"
                col_m6.metric("å¹³å‡æ¯ç¬”æˆäº¤é¢", avg_trade_display)
                
                # ä»·æ ¼å˜åŠ¨
                price_change = overall_metrics.get('price_change_pct')
                price_change_display = f"{price_change:.4f}%" if isinstance(price_change, (int, float)) else "N/A"
                st.metric("ä»·æ ¼å˜åŠ¨ç™¾åˆ†æ¯”", price_change_display)
                st.divider()
                
                # --- 3. æ–°å¢ï¼šå¤§å•åˆ†æå±•ç¤º (ä» overall -> large_trades_analysis æå–) ---
                st.subheader("å¤§å•åˆ†æ (P98):") # å‡è®¾åªæ˜¾ç¤º P98
                large_analysis_all = overall_metrics.get('large_trades_analysis', {})
                # --- ä¿®æ­£ï¼šä½¿ç”¨å­—ç¬¦ä¸² "98" ä½œä¸ºé”®è®¿é—® --- 
                p98_analysis = large_analysis_all.get("98", {}) # å®‰å…¨è·å– P98 åˆ†æå­—å…¸ (ä½¿ç”¨å­—ç¬¦ä¸²é”®)
                
                if p98_analysis and not p98_analysis.get('error'): # ç¡®ä¿æœ‰æ•°æ®ä¸”æ²¡æœ‰é”™è¯¯
                    col_l1, col_l2, col_l3 = st.columns(3)
                    
                    threshold = p98_analysis.get('large_order_threshold_quote')
                    th_display = f"{threshold:,.2f}" if isinstance(threshold, (int, float)) else "N/A"
                    col_l1.metric("P98 å¤§å•é˜ˆå€¼", th_display)
                    
                    count = p98_analysis.get('large_trades_count')
                    col_l2.metric("P98 å¤§å•æ•°é‡", str(count) if count is not None else "N/A")
                    
                    large_vol = p98_analysis.get('large_total_quote_volume')
                    lv_display = f"{large_vol:,.2f}" if isinstance(large_vol, (int, float)) else "N/A"
                    col_l3.metric("P98 å¤§å•æ€»é¢", lv_display)
                    
                    col_l4, col_l5, col_l6 = st.columns(3)
                    
                    large_tvr = p98_analysis.get('large_taker_volume_ratio')
                    ltvr_display = f"{large_tvr:.2f}" if isinstance(large_tvr, (int, float)) else "N/A"
                    col_l4.metric("P98 å¤§å•ä¹°å–é‡æ¯”", ltvr_display)
                    
                    buy_vwap = p98_analysis.get('large_taker_buy_vwap')
                    bvwap_display = f"{buy_vwap:.2f}" if isinstance(buy_vwap, (int, float)) else "N/A"
                    col_l5.metric("P98 å¤§å•ä¹°æ–¹VWAP", bvwap_display)
                    
                    sell_vwap = p98_analysis.get('large_taker_sell_vwap')
                    svwap_display = f"{sell_vwap:.2f}" if isinstance(sell_vwap, (int, float)) else "N/A"
                    col_l6.metric("P98 å¤§å•å–æ–¹VWAP", svwap_display)
                    
                else:
                    st.info("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ P98 å¤§å•åˆ†ææ•°æ®ã€‚")

                st.divider()
                
                # --- 4. åŸå§‹ JSON (ä¿æŒ) ---
                with st.expander("æŸ¥çœ‹åŸå§‹æˆäº¤é‡JSONæ•°æ®", expanded=False):
                    st.json(result_dict_vm)
                # --- æ˜¾ç¤ºç»“æŸ ---
            elif result_dict_vm.get('warning'): # å¤„ç†å¯èƒ½çš„è­¦å‘Šä¿¡æ¯
                 st.warning(result_dict_vm['warning'])
                 with st.expander("æŸ¥çœ‹åŸå§‹è¿”å›å†…å®¹", expanded=False):
                      st.write(result_dict_vm.get('raw_result'))
            else:
                 # å¤„ç†æœªçŸ¥è¿”å›ç±»å‹
                 st.warning("æˆäº¤é‡åˆ†æè¿”å›æ•°æ®æ ¼å¼æœªçŸ¥æˆ–æ— æ³•è§£æã€‚")
                 st.write("åŸå§‹è¿”å›å†…å®¹:", result_dict_vm)


# --- æ–°å¢ï¼šæˆäº¤é‡è‡ªåŠ¨æŠ¥å‘Šæ ‡ç­¾é¡µ ---
with tab_volume_auto:
    st.header(f"æˆäº¤æµè‡ªåŠ¨åˆ†ææŠ¥å‘Š (Top {TOP_N_SYMBOLS} äº¤æ˜“é‡)")
    st.markdown(f"**é‡è¦æç¤º:** æ­¤åŠŸèƒ½ä¾èµ–ä¸€ä¸ªç‹¬ç«‹çš„**åå°æˆäº¤æµåˆ†æè„šæœ¬**æ¯ {AUTO_ANALYSIS_INTERVAL_MINUTES} åˆ†é’Ÿè¿è¡Œä¸€æ¬¡ï¼Œå¹¶å°†ç»“æœå†™å…¥ `{AUTO_VOLUME_RESULTS_FILE}` æ–‡ä»¶ã€‚") # ä½¿ç”¨æ–°å¸¸é‡
    st.markdown("è¯·ç¡®ä¿è¯¥åå°è„šæœ¬å·²æ­£ç¡®é…ç½®å¹¶æ­£åœ¨è¿è¡Œã€‚")

    if st.button("æ‰‹åŠ¨åˆ·æ–°æˆäº¤æµæŠ¥å‘Š", key="volume_auto_refresh_button"):
        st.rerun()

    auto_volume_results_data = None
    last_volume_update_time_str = "æœªçŸ¥"
    volume_file_error = None

    if os.path.exists(AUTO_VOLUME_RESULTS_FILE): # ä½¿ç”¨æ–°å¸¸é‡
        try:
            volume_file_mod_time = os.path.getmtime(AUTO_VOLUME_RESULTS_FILE)
            last_volume_update_time = datetime.fromtimestamp(volume_file_mod_time)
            if datetime.now() - last_volume_update_time > timedelta(minutes=AUTO_ANALYSIS_INTERVAL_MINUTES * 3):
                 st.warning(f"æˆäº¤æµç»“æœæ–‡ä»¶ `{AUTO_VOLUME_RESULTS_FILE}` æœ€åæ›´æ–°äº {last_volume_update_time.strftime('%Y-%m-%d %H:%M:%S')}ï¼Œå¯èƒ½å·²è¿‡æœŸã€‚")
            last_volume_update_time_str = last_volume_update_time.strftime('%Y-%m-%d %H:%M:%S')
            with open(AUTO_VOLUME_RESULTS_FILE, 'r', encoding='utf-8') as f:
                auto_volume_results_data = json.load(f)
        except json.JSONDecodeError as e:
            volume_file_error = f"è¯»å–æˆäº¤æµç»“æœæ–‡ä»¶ `{AUTO_VOLUME_RESULTS_FILE}` æ—¶ JSON è§£æå¤±è´¥: {e}"
            logger.error(volume_file_error)
        except Exception as e:
            volume_file_error = f"è¯»å–æˆäº¤æµç»“æœæ–‡ä»¶ `{AUTO_VOLUME_RESULTS_FILE}` æ—¶å‘ç”Ÿé”™è¯¯: {e}"
            logger.error(volume_file_error, exc_info=True)
    else:
        volume_file_error = f"æˆäº¤æµç»“æœæ–‡ä»¶ `{AUTO_VOLUME_RESULTS_FILE}` ä¸å­˜åœ¨ã€‚è¯·å¯åŠ¨åå°æˆäº¤æµåˆ†æè„šæœ¬ã€‚"

    st.caption(f"æˆäº¤æµæŠ¥å‘Šæ•°æ®æœ€åæ›´æ–°æ—¶é—´: {last_volume_update_time_str}")

    if volume_file_error:
        st.error(volume_file_error)
    elif not auto_volume_results_data or not isinstance(auto_volume_results_data, dict):
         st.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æˆäº¤æµè‡ªåŠ¨åˆ†æç»“æœæˆ–ç»“æœæ ¼å¼ä¸æ­£ç¡®ã€‚")
         logger.warning(f"æˆäº¤æµè‡ªåŠ¨åˆ†æç»“æœæ–‡ä»¶å†…å®¹æ— æ•ˆæˆ–éå­—å…¸: {type(auto_volume_results_data)}")
    else:
        # --- æ›´æ–°ï¼šå‡†å¤‡æˆäº¤é‡æ‘˜è¦æ•°æ® ---
        summary_volume_data_list = []
        failed_volume_symbols = []
        logger.info("å¼€å§‹ä¸ºæˆäº¤æµè‡ªåŠ¨æŠ¥å‘Šå‡†å¤‡æ‘˜è¦æ•°æ®...")
        
        for symbol_va, result_dict_va in auto_volume_results_data.items():
            if isinstance(result_dict_va, dict):
                explicit_error_va = result_dict_va.get('error')
                
                # --- æ›´æ–°æˆåŠŸåˆ¤æ–­æ¡ä»¶ --- 
                # æ£€æŸ¥æ²¡æœ‰é”™è¯¯ï¼Œå¹¶ä¸”åŒ…å«è¡¨ç¤ºæˆåŠŸçš„å…³é”®é”® (ä¾‹å¦‚ interpretation å’Œ overall)
                if explicit_error_va is None and 'interpretation' in result_dict_va and 'overall' in result_dict_va:
                    try:
                         # --- æå–æˆäº¤é‡æ‘˜è¦ä¿¡æ¯ (ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„) ---
                         interpretation_data = result_dict_va.get('interpretation', {})
                         overall_data = result_dict_va.get('overall', {})
                         
                         score_va = interpretation_data.get('bias_score', 'N/A')
                         score_display_va = f"{score_va:.1f}" if isinstance(score_va, (int, float)) else str(score_va)
                         
                         delta_vol_va = overall_data.get('delta_volume')
                         delta_display_va = f"{delta_vol_va:,.2f}" if isinstance(delta_vol_va, (int, float)) else "N/A"
                         
                         tvr_va = overall_data.get('taker_volume_ratio')
                         tvr_display_va = f"{tvr_va:.2f}" if isinstance(tvr_va, (int, float)) else "N/A"
                         
                         # ä» interpretation -> overall -> details æå–ç¬¬ä¸€æ¡è¯¦æƒ…ä½œä¸ºæ‘˜è¦
                         details_list_va = interpretation_data.get('overall', {}).get('details', [])
                         primary_detail_va = ""
                         if details_list_va and isinstance(details_list_va[0], str):
                              cleaned_detail = details_list_va[0].split(" : ", 1)[-1] if " : " in details_list_va[0] else details_list_va[0]
                              primary_detail_va = cleaned_detail
                         # --- æå–ç»“æŸ --- 
                              
                         summary_volume_data_list.append({
                             "äº¤æ˜“å¯¹": symbol_va,
                             "è¯„åˆ†": score_display_va,
                             "ä¸»è¦è¯¦æƒ…": primary_detail_va, # ä½¿ç”¨æå–çš„ç¬¬ä¸€æ¡è¯¦æƒ…
                             "Deltaæˆäº¤é‡": delta_display_va,
                             "ä¸»åŠ¨ä¹°å–é‡æ¯”": tvr_display_va,
                             # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šåˆ— (å¦‚æ€»æˆäº¤é¢ç­‰)
                             "åŸå§‹è¯„åˆ†": score_va if isinstance(score_va, (int, float)) else -999 # ç”¨äºæ’åº
                         })
                    except Exception as e: # æ•è·æå–æ•°æ®æ—¶çš„æ„å¤–é”™è¯¯
                         logger.error(f"ä¸º {symbol_va} æå–æ‘˜è¦æ•°æ®æ—¶å‡ºé”™: {e}", exc_info=True)
                         failed_volume_symbols.append(symbol_va) # æå–å¤±è´¥ä¹Ÿç®—å¤±è´¥
                else:
                    # å¦‚æœæœ‰é”™è¯¯æˆ–ç¼ºå°‘å…³é”®é”®ï¼Œåˆ™æ ‡è®°ä¸ºå¤±è´¥
                    failed_volume_symbols.append(symbol_va)
                    if explicit_error_va:
                         logger.warning(f"è‡ªåŠ¨æŠ¥å‘Šæ‘˜è¦è·³è¿‡ {symbol_va}: åˆ†æè¿”å›é”™è¯¯ '{explicit_error_va}'")
                    else:
                         logger.warning(f"è‡ªåŠ¨æŠ¥å‘Šæ‘˜è¦è·³è¿‡ {symbol_va}: ç¼ºå°‘ interpretation æˆ– overall é”®ã€‚")
            else:
                 # å¦‚æœé¡¶å±‚ä¸æ˜¯å­—å…¸ï¼Œæ ‡è®°ä¸ºå¤±è´¥
                 failed_volume_symbols.append(symbol_va)
                 logger.error(f"è‡ªåŠ¨æŠ¥å‘Šæ‘˜è¦è·³è¿‡ {symbol_va}: é¡¶å±‚æ•°æ®ä¸æ˜¯å­—å…¸ã€‚")
                 
        logger.info(f"æˆäº¤æµæ‘˜è¦æ•°æ®å‡†å¤‡å®Œæˆã€‚æˆåŠŸ: {len(summary_volume_data_list)}, å¤±è´¥/è·³è¿‡: {len(failed_volume_symbols)}.")

        # --- æ›´æ–°ï¼šæ˜¾ç¤ºæˆäº¤é‡æ‘˜è¦è¡¨ ---
        st.markdown("---")
        st.subheader("ğŸ“Š æˆäº¤æµè‡ªåŠ¨åˆ†ææ‘˜è¦")
        if summary_volume_data_list:
            summary_volume_df = pd.DataFrame(summary_volume_data_list)
            # æŒ‰è¯„åˆ†æ’åº (å¯é€‰)
            summary_volume_df = summary_volume_df.sort_values(by="åŸå§‹è¯„åˆ†", ascending=False).drop(columns=["åŸå§‹è¯„åˆ†"])
            # (å¯ä»¥æ·»åŠ æ ·å¼å‡½æ•°ï¼Œä¾‹å¦‚æ ¹æ®è¯„åˆ†é«˜äº®)
            display_cols_va = ["äº¤æ˜“å¯¹", "è¯„åˆ†", "ä¸»è¦è¯¦æƒ…", "Deltaæˆäº¤é‡", "ä¸»åŠ¨ä¹°å–é‡æ¯”"]
            valid_cols_va = [col for col in display_cols_va if col in summary_volume_df.columns]
            st.dataframe(summary_volume_df[valid_cols_va], use_container_width=True, hide_index=True)
        else:
            st.info("å½“å‰æ²¡æœ‰å¯ç”¨çš„æˆäº¤æµæˆåŠŸåˆ†ææ‘˜è¦ã€‚")
        if failed_volume_symbols:
             # æ›´æ–°æç¤ºä¿¡æ¯ï¼Œåªæ˜¾ç¤ºçœŸæ­£å¤±è´¥æˆ–æ•°æ®ä¸å®Œæ•´çš„
             st.caption(f"æ³¨æ„: ä»¥ä¸‹äº¤æ˜“å¯¹æˆäº¤æµåˆ†æå¤±è´¥æˆ–æ•°æ®ä¸å®Œæ•´: {', '.join(failed_volume_symbols)}")

        # --- æ›´æ–°ï¼šæˆäº¤é‡è¯¦ç»†åˆ†æ (æŠ˜å ) é€»è¾‘ ---
        st.divider()
        st.subheader("ğŸ” å„äº¤æ˜“å¯¹æˆäº¤æµè¯¦ç»†åˆ†æ")
        for symbol_va_detail, result_dict_va_detail in auto_volume_results_data.items():
            # åªä¸ºçœŸæ­£æˆåŠŸçš„å¸ç§æ˜¾ç¤ºå±•å¼€åŒºåŸŸ
            if symbol_va_detail not in failed_volume_symbols and isinstance(result_dict_va_detail, dict):
                with st.expander(f"**{symbol_va_detail}** æˆäº¤æµè¯¦ç»†åˆ†æ", expanded=False):
                     # --- æ›´æ–°ï¼šæ˜¾ç¤ºæˆäº¤é‡è¯¦æƒ… (å¤ç”¨æ‰‹åŠ¨åˆ†æçš„é€»è¾‘) ---
                     # st.info(f"æ˜¾ç¤º {symbol_va_detail} çš„æˆäº¤æµè¯¦ç»†åˆ†æç»“æœã€‚") # ç§»é™¤æ—§æç¤º
                     
                     # 1. è¯„åˆ† & åˆ†æè¯¦æƒ…
                     score_va_d = None
                     try: score_va_d = result_dict_va_detail.get('interpretation', {}).get('bias_score')
                     except AttributeError: pass
                     if score_va_d is not None: st.metric("è¯„åˆ† (Bias Score)", f"{score_va_d:.1f}" if isinstance(score_va_d, (int, float)) else str(score_va_d))
                     else: st.metric("è¯„åˆ†", "N/A")
                     
                     details_list_va_d = None
                     try: details_list_va_d = result_dict_va_detail.get('interpretation', {}).get('overall', {}).get('details')
                     except AttributeError: pass
                     if isinstance(details_list_va_d, list) and details_list_va_d:
                         st.subheader("åˆ†æè¯¦æƒ…:")
                         for item_d in details_list_va_d:
                              if isinstance(item_d, str): cleaned_item_d = item_d.split(" : ", 1)[-1] if " : " in item_d else item_d; st.markdown(f"- {cleaned_item_d}")
                              else: st.markdown(f"- {item_d}")
                     else: st.info("æœªæ‰¾åˆ°åˆ†æè¯¦æƒ…ã€‚")
                     st.divider()
                     
                     # 2. å…³é”®æŒ‡æ ‡
                     st.subheader("å…³é”®æŒ‡æ ‡:")
                     overall_metrics_d = result_dict_va_detail.get('overall', {})
                     # ... (çœç•¥ä¸æ‰‹åŠ¨åˆ†æç±»ä¼¼çš„ st.columns å’Œ st.metric ä»£ç æ¥æ˜¾ç¤ºå…³é”®æŒ‡æ ‡) ...
                     col_m1d, col_m2d, col_m3d = st.columns(3)
                     delta_vol_d = overall_metrics_d.get('delta_volume'); delta_display_d = f"{delta_vol_d:,.2f}" if isinstance(delta_vol_d, (int, float)) else "N/A"; col_m1d.metric("Delta æˆäº¤é‡", delta_display_d)
                     tvr_d = overall_metrics_d.get('taker_volume_ratio'); tvr_display_d = f"{tvr_d:.2f}" if isinstance(tvr_d, (int, float)) else "N/A"; col_m2d.metric("ä¸»åŠ¨ä¹°å–é‡æ¯” (ä¹°/å–)", tvr_display_d)
                     ttr_d = overall_metrics_d.get('taker_trade_ratio'); ttr_display_d = f"{ttr_d:.2f}" if isinstance(ttr_d, (int, float)) else "N/A"; col_m3d.metric("ä¸»åŠ¨ä¹°å–ç¬”æ•°æ¯” (ä¹°/å–)", ttr_display_d)
                     col_m4d, col_m5d, col_m6d = st.columns(3)
                     total_vol_d = overall_metrics_d.get('total_quote_volume'); total_vol_display_d = f"{total_vol_d:,.2f}" if isinstance(total_vol_d, (int, float)) else "N/A"; col_m4d.metric("æ€»æˆäº¤é¢", total_vol_display_d)
                     trades_ps_d = overall_metrics_d.get('trades_per_second'); tps_display_d = f"{trades_ps_d:.2f}" if isinstance(trades_ps_d, (int, float)) else "N/A"; col_m5d.metric("æ¯ç§’æˆäº¤ç¬”æ•°", tps_display_d)
                     avg_trade_size_d = overall_metrics_d.get('avg_trade_size_quote'); avg_trade_display_d = f"{avg_trade_size_d:,.2f}" if isinstance(avg_trade_size_d, (int, float)) else "N/A"; col_m6d.metric("å¹³å‡æ¯ç¬”æˆäº¤é¢", avg_trade_display_d)
                     price_change_d = overall_metrics_d.get('price_change_pct'); price_change_display_d = f"{price_change_d:.4f}%" if isinstance(price_change_d, (int, float)) else "N/A"; st.metric("ä»·æ ¼å˜åŠ¨ç™¾åˆ†æ¯”", price_change_display_d)
                     st.divider()
                     
                     # 3. å¤§å•åˆ†æ (P98)
                     st.subheader("å¤§å•åˆ†æ (P98):")
                     large_analysis_all_d = overall_metrics_d.get('large_trades_analysis', {})
                     # --- ä¿®æ­£ï¼šä½¿ç”¨å­—ç¬¦ä¸² "98" ä½œä¸ºé”®è®¿é—® --- 
                     p98_analysis_d = large_analysis_all_d.get("98", {}) # (ä½¿ç”¨å­—ç¬¦ä¸²é”®)
                     if p98_analysis_d and not p98_analysis_d.get('error'):
                         # ... (å†…éƒ¨æ˜¾ç¤ºé€»è¾‘ä¿æŒä¸å˜) ...
                         col_l1d, col_l2d, col_l3d = st.columns(3)
                         threshold_d = p98_analysis_d.get('large_order_threshold_quote'); th_display_d = f"{threshold_d:,.2f}" if isinstance(threshold_d, (int, float)) else "N/A"; col_l1d.metric("P98 å¤§å•é˜ˆå€¼", th_display_d)
                         count_d = p98_analysis_d.get('large_trades_count'); col_l2d.metric("P98 å¤§å•æ•°é‡", str(count_d) if count_d is not None else "N/A")
                         large_vol_d = p98_analysis_d.get('large_total_quote_volume'); lv_display_d = f"{large_vol_d:,.2f}" if isinstance(large_vol_d, (int, float)) else "N/A"; col_l3d.metric("P98 å¤§å•æ€»é¢", lv_display_d)
                         col_l4d, col_l5d, col_l6d = st.columns(3)
                         large_tvr_d = p98_analysis_d.get('large_taker_volume_ratio'); ltvr_display_d = f"{large_tvr_d:.2f}" if isinstance(large_tvr_d, (int, float)) else "N/A"; col_l4d.metric("P98 å¤§å•ä¹°å–é‡æ¯”", ltvr_display_d)
                         buy_vwap_d = p98_analysis_d.get('large_taker_buy_vwap'); bvwap_display_d = f"{buy_vwap_d:.2f}" if isinstance(buy_vwap_d, (int, float)) else "N/A"; col_l5d.metric("P98 å¤§å•ä¹°æ–¹VWAP", bvwap_display_d)
                         sell_vwap_d = p98_analysis_d.get('large_taker_sell_vwap'); svwap_display_d = f"{sell_vwap_d:.2f}" if isinstance(sell_vwap_d, (int, float)) else "N/A"; col_l6d.metric("P98 å¤§å•å–æ–¹VWAP", svwap_display_d)
                     else: st.info("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ P98 å¤§å•åˆ†ææ•°æ®ã€‚")
                     st.divider()

                     # 4. åŸå§‹ JSON
                     st.subheader("åŸå§‹æˆäº¤æµJSONæ•°æ®:")
                     st.json(result_dict_va_detail)
                     # --- æ˜¾ç¤ºç»“æŸ ---
                     
            # å¤„ç†å®é™…å¤±è´¥çš„å¸ç§ (åœ¨ failed_volume_symbols åˆ—è¡¨ä¸­çš„)
            elif symbol_va_detail in failed_volume_symbols and isinstance(result_dict_va_detail, dict) and (explicit_error_va_detail := result_dict_va_detail.get('error')):
                 # ç›´æ¥æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼Œä¸ä½¿ç”¨ expander
                 st.error(f"åˆ†æ {symbol_va_detail} æ—¶å‡ºé”™: {explicit_error_va_detail}")
                 tb_va = result_dict_va_detail.get('traceback')
                 if tb_va:
                     # å…è®¸ä¸ºé”™è¯¯ä¿¡æ¯ä½¿ç”¨ expander
                     with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ… (Traceback)", expanded=False):
                          st.code(tb_va, language='python')
                 st.divider() # æ·»åŠ åˆ†éš”ç¬¦
                 
        # --- è¯¦ç»†åˆ†ææ˜¾ç¤ºç»“æŸ ---

# --- é¡µè„š (ä¿æŒä¸å˜) ---
st.markdown("---")
# ... (å†…æµ‹äº¤æµå’Œå…è´£å£°æ˜ä»£ç ä¿æŒä¸å˜) ...
with st.expander("å†…æµ‹äº¤æµ (ç‚¹å‡»å±•å¼€)", expanded=False):
    st.markdown("æœ¬å·¥å…·ç›®å‰å¤„äºå†…éƒ¨æµ‹è¯•é˜¶æ®µï¼Œæ¬¢è¿æ‚¨åŠ å…¥äº¤æµç¾¤ï¼Œåˆ†äº«ä½¿ç”¨ä½“éªŒã€åé¦ˆé—®é¢˜ã€æå‡ºå®è´µå»ºè®®æˆ–ä¸€èµ·æ¢è®¨ K çº¿ä¸æˆäº¤æµåˆ†ææ€è·¯ï¼è¯·æ·»åŠ å¾®ä¿¡å·ï¼šQ54855742ï¼Œå¤‡æ³¨'Kçº¿åˆ†æå·¥å…·'ï¼Œæˆ‘ä¼šé‚€è¯·æ‚¨å…¥ç¾¤ã€‚") # æ›´æ–°æ–‡æœ¬
with st.expander("å…è´£å£°æ˜ (ç‚¹å‡»å±•å¼€)", expanded=False):
    st.caption("é‡è¦æç¤ºï¼šåŠ å¯†è´§å¸å¸‚åœºå…·æœ‰é«˜é£é™©æ€§ï¼Œä»·æ ¼æ³¢åŠ¨å‰§çƒˆã€‚æœ¬å·¥å…·æä¾›çš„æ‰€æœ‰åˆ†æã€æ•°æ®ã€å›¾è¡¨å’Œä¿¡æ¯ä»…åŸºäºå†å²æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡ç”Ÿæˆï¼Œæ—¨åœ¨æä¾›å¸‚åœºè§‚å¯Ÿå’Œå­¦ä¹ å‚è€ƒï¼Œä¸æ„æˆä»»ä½•å½¢å¼çš„æŠ•èµ„å»ºè®®ã€æ¨èæˆ–è´¢åŠ¡æ„è§ã€‚ç”¨æˆ·åº”è‡ªè¡Œæ‰¿æ‹…æ‰€æœ‰æŠ•èµ„å†³ç­–çš„é£é™©ã€‚åœ¨åšå‡ºä»»ä½•æŠ•èµ„å†³ç­–å‰ï¼Œè¯·åŠ¡å¿…è¿›è¡Œç‹¬ç«‹ç ”ç©¶ï¼Œå¹¶å’¨è¯¢åˆæ ¼çš„è´¢åŠ¡é¡¾é—®ã€‚æœ¬å·¥å…·çš„å¼€å‘è€…ä¸å¯¹ä»»ä½•å› ä½¿ç”¨æˆ–ä¾èµ–æœ¬å·¥å…·ä¿¡æ¯è€Œäº§ç”Ÿçš„ç›´æ¥æˆ–é—´æ¥æŸå¤±è´Ÿè´£ã€‚")

# (ç§»é™¤æœ«å°¾å¤šä½™çš„æ ‡è®°) 